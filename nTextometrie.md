---
title: Notes sur la textométrie
author: emchateau
since: 2016-10
tags: textométrie
---
# Notes sur la textométrie

## Textométrie

Selon M. Tournier, la lexicometrie aussi appelée : logométrie, analyse automatique,

« **statistique linguistique** (Guiraud, 1959, 1960), **statistique lexicale** ou **linguistique quantitative** (Muller, 1964, 1967, 1973, 1979), **statistique textuelle** (Salem 1987, 1994), voire **analyse des données en linguistique** (Benzecri 1981), **la lexicométrie**  (Tournier 1975, Lafon 1984) n’est pas une théorie mais une méthodologie  d’étude du discours, qui se veut exhaustive, systématique est  automatisée. » Tournier M., 2002, p. 342-343.

Michel Pêcheux 1969, Analyse automatique du discours (AAD) à partir d’une approche syntaxique à la suite de Z. Harris. Mais son approche nécessitait une préparation importante du corpus. L’usage d’une codification thématique mobilisant déjà une analyse et un jugement (Achard 1991). —> Volonté de travailler sur la langue naturelle, sans préparation particulière du texte.

G. Herdan (1964) considère la linguistique statistique comme « une branche de la linguistique structurale, avec pour principale fonction la description statistique du fonctionnement (dans des corpus de textes) des unités définies par le linguiste aux différents niveaux de l’analyse linguistique (phonologique, lexical, phrastique) » cf. Lebart L., Salem A., 1994, p.16.

D. Mayaffre historien discours politiques

Mayaffre D., 2000, p.749. explique que ses connaissances linguistiques ne lui suffisent pas pour nourrir le débat épistémologique sur le lien entre Histoire et Linguistique dans l’analyse du discours

 ni à la méthode binomiale ni le modèle hypergéométrique en statistique lexicale

fait du mot un “objet réticulaire” pour Mayaffre

Traitement lexicographique qui consiste à traiter le texte sans lemmatisation (pour lemmatiser le vocabulaire d’un texte écrit en français, on ramène en général les formes verbales à l’infinitif, les substantifs au singulier, les adjectifs au masculin singulier, les formes élidées à la forme sans élision). Les formes apparaissent donc telles qu’elles ont été saisies : une forme au singulier et au pluriel comptant pour deux formes différentes, de même qu’un adjectif féminin ou masculin, ou encore un verbe sous ses différentes formes conjuguées.

Le corpus est distribué en plusieurs parties dans l’édition avant l’opération de segmentation. On y introduit différentes clés qui correspondent à des variables dont on dispose par ailleurs et qui peuvent permettent, par exemple, d’identifier des locuteurs puis de les regrouper par âge, sexe, niveau d’étude, etc.

Les traitements lexicométriques reposent sur une segmentation automatique du texte en occurrences de formes graphiques à partir de la définition d’un sous-ensemble de caractères délimiter. Les autres caractères étant considérés comme non délimiter. Chaque suite de caractères bornée à ses deux extrémités par des caractères délimiter est considérée comme une occurence. Et deux suites de caractères non délimiter indentifiques constituent deux occurrences d’une même forme. « La forme est un archétype correspondant à une ensemble d’occurrences identiques. L’ensemble des formes d’un texte constitue son vocabulaire. » (Leimdorfer et Salem 1995)

Cette segmentation en formes graphiques permet ensuite de considérer le texte comme une suite d’occurrences séparées entre elles par un ou plusieurs caractères délimiter. « On regroupe sous le terme de lexicométrie toute une série de méthodes qui permettent d’opérer, à partir d’une segmentation, des réorganisations formelles de la séquence textuelle et des analyses statistiques portant sur le vocabulaire. » (Leimdorfer et Salem 1995)

- méthodes documentaires qui opèrent une simple réorganisation de la surface textuelle
- méthodes qui opèrent, pour chaque texte pris isolément, des comptages et des calculs d’indices statistiques
- les méthodes statistiques contrastives qui produisent des résultats portant sur le vocabulaire de chacun des textes par rapport à l’ensemble des textes réunis dans un même corpus à des fins de comparaisons.

Logiciels qui fournissent après la segmentation série de documents permettant de mieux appréhender le vocabulaire du corpus

- L’*index alphabétique* permet de vérifier la saisie du texte, de rapprocher les utilisations du singulier et du pluriel d’un même substantif, les différentes flexions d’un verbe, etc.
- L’*index hiérarchique*, dans lesquels les formes sont classées par fréquence décroissante, permet d’examiner les formes les plus utilisées
- Les *concordances* permettent, pour chaque forme, de rassembler l’ensemble des contextes dans lesquels la forme apparaît
- Les *inventaires de segments répétés* permettent de repérer les séquences de formes qui apparaissent à plusieurs endroits du texte
- le *calcul de spécificités* permet de dégager les formes et les segments qui se trouvent être particulièrement employés (ou, au contraire, particulièrement sous-employés) dans chacune des parties du corpus.

[...]

L’outil lexicométrique s’avère, du point de vue de l’analyse de discours, d’un très grand intérêt, dans trois directions principales :

- par les données quantitatives fournies, les comparaisons et les vérifications qu’il permet ;
- comme outil de repérage de pistes de recherche, et comme premier bilan d’un corpus ;
- comme outil heuristique puissant, entraînant à des allers-retours fructueux entre le texte analysé et les données produites. Il incite à une définition plus fine des données et à des comparaisons vers d’autres corpus. Il oblige également à une réflexion sur le statut du « quantitatif » dans le discours à l’écrit et à l’oral.

D’un point de vue pratique, il est particulièrement utile si **plusieurs éléments se trouvent réunis** :

- si le corpus est relativement important, difficilement maîtrisable par une analyse fine de fragments ; mais des informations intéressantes se dégagent avec des corpus de quelques dizaines de pages seulement ;
- si la saisie sous traitement de texte peut être faite sans difficultés particulières, et de manière économique (en temps de travail notamment) ;
- si le corpus est suffisamment connu, déjà analysé pour que les indications statistiques données puissent prendre sens et orienter la recherche ; lorsque cette connaissance de l’« l’intérieur » n’existe pas, les données fournies par le calcul indiquent autant de pistes possibles, mais qu’il est difficile d’examiner exhaustivement. Par contre, lorsque le corpus a déjà été analysé en partie ou que l’on dispose de pistes de recherche identifiées, l’outil lexicométrique devient un « multiplicateur » de recherche remarquable, par les allers-retours continuels qu’il permet entre l’analyse de fragments, les données statistiques et les nouvelles demande de tri que l’on peut formuler.

(Leimdorfer, François et André Salem. 1995. « Usages de la lexicométrie en analyse de discours ». *Cahiers de Sciences humaines* 31 (1) : 131-143. décrivent ensuite l’exemple de thèses)

## Outils

### TXM

Le [Projet Textométrie](http://textometrie.ens-lyon.fr) fédère des recherches et des développements logiciels en textométrie autour de la création d’une plateforme logicielle ouverte.

### Medite

http://obvil.paris-sorbonne.fr/developpements/medite

### HyperBase

## Bibliographie

PINCEMIN Bénédicte, HEIDEN Serge (2008) - "Qu’est-ce que la textométrie ? Présentation", *Site du projet Textométrie *, [http://textometrie.ens-lyon.fr/spip.php?rubrique80](http://textometrie.ens-lyon.fr/spip.php?rubrique80)
